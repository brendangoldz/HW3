{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "508b1e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data_handler import DataHandler\n",
    "from log_regression import LogisticalRegression\n",
    "from calculations import Calculations\n",
    "\n",
    "TERMINATION_VALUE = 2^-32\n",
    "ITERATIONS = 10000\n",
    "LEARNING_RATE = 0.001\n",
    "dh = DataHandler(\"spambase.data\")\n",
    "data = dh.parse_data_no_header()\n",
    "data = dh.shuffle_data(data)\n",
    "data_train, data_test = dh.split_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c449fcca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3067, 57),\n",
       " (3067, 1),\n",
       " (1533, 57),\n",
       " (1533, 1),\n",
       " array([0.59667427, 0.40332573]),\n",
       " array([0.62426614, 0.37573386]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX, tY = dh.getXY(data_train, -1, -1)\n",
    "mean, std = dh.zscore_data(tX)\n",
    "vX, vY = dh.getXY(data_test, -1, -1)\n",
    "tX_, tPriors, tMeans, tVars = dh.dynamic_split(tX, tY, mean, std)\n",
    "vX_, vPriors, vMeans, vVars = dh.dynamic_split(vX, vY, mean, std)\n",
    "tX.shape, tY.shape, vX.shape, vY.shape, tPriors, vPriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb9ea31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gnb(x_val, x_mean, x_var):\n",
    "    equation_1 = 0\n",
    "    equation_2 = 0\n",
    "    if x_var < 0.0001:\n",
    "        x_var = 0.0001\n",
    "    equation_1 = 1/(np.sqrt(2 * np.pi * x_var))    \n",
    "\n",
    "    e2denom = np.square(2 * x_var)\n",
    "    e2num = np.square(x_val - x_mean)\n",
    "\n",
    "    equation_2 = np.exp(-(e2num/e2denom))\n",
    "        \n",
    "    prob = equation_1 * equation_2\n",
    "    return prob\n",
    "\n",
    "def getPFC(priors, x, Y):\n",
    "    probs_per_class = []\n",
    "    total_probability = 0\n",
    "    for i in range(len(np.unique(Y))):\n",
    "        prior = priors[i]\n",
    "        gnb_ = 1\n",
    "        for j in range(x.shape[0]):\n",
    "            gnb_ = gnb_ * gnb(x[j], tMeans[i][j], tVars[i][j])\n",
    "        total_probability += (np.multiply(prior, gnb_))\n",
    "        probs_per_class.append(np.multiply(prior, gnb_))\n",
    "    return probs_per_class, total_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90c682d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8408349641226354, 0.8888888888888888, 0.7398843930635838, 0.807570977917981)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = []\n",
    "classifiers = np.unique(vY)\n",
    "for i in range(vX.shape[0]):\n",
    "    probs, total_probability = getPFC(vPriors, vX[i,:], vY)\n",
    "    probs = probs/(total_probability+0.0001)\n",
    "    max_prob_ind = probs.argmax()\n",
    "    preds.append(classifiers[max_prob_ind])\n",
    "\n",
    "calc = Calculations(vY, preds)\n",
    "\n",
    "acc, recall, fmeasure, precision = calc.evaluate()\n",
    "acc, recall, fmeasure, precision "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
